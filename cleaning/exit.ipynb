{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c22c775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad52efc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 loaded\n",
      "2019 loaded\n",
      "2020 loaded\n",
      "2021 loaded\n",
      "2022 loaded\n",
      "acchome_accepted\n",
      "aig\n",
      "auto_xfer_school\n",
      "base_school\n",
      "count_row_pre\n",
      "count_row_state\n",
      "dc_g9year\n",
      "den\n",
      "eds\n",
      "effective_exit_code\n",
      "effective_g9year\n",
      "els\n",
      "els_year_exited\n",
      "en_five_year\n",
      "en_g9school\n",
      "en_g9year\n",
      "ethnic\n",
      "ex_exit_code\n",
      "ex_xfer_school\n",
      "exit_exempt\n",
      "fcs\n",
      "g9year_missing\n",
      "gdvr\n",
      "gdvr_document_type\n",
      "gdvr_school\n",
      "gdvr_year\n",
      "hms\n",
      "in_cohort\n",
      "init_collection\n",
      "init_grade\n",
      "init_year\n",
      "last_collection\n",
      "last_year\n",
      "lea\n",
      "mastid\n",
      "mig\n",
      "num\n",
      "ps_g9year\n",
      "rc_g9year\n",
      "schlcode\n",
      "sex\n",
      "swd\n",
      "swd_latest_school\n",
      "swd_latest_year\n",
      "year\n"
     ]
    }
   ],
   "source": [
    "# 1) Load each year\n",
    "dfs = {}\n",
    "for year in range(18, 23):    # 2018–2022\n",
    "    path = f\"/Users/danielmatten/desktop/m/exit_pub20{year}.sas7bdat\"\n",
    "    try:\n",
    "        df = pd.read_sas(path)\n",
    "        df.columns = df.columns.str.lower()\n",
    "        dfs[year] = df\n",
    "        print(f\"20{year} loaded\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {path} not found, skipping.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in 20{year}: {e}, skipping.\")\n",
    "\n",
    "# 2) Find the core columns present in every year\n",
    "core_cols = set(dfs[next(iter(dfs))].columns)\n",
    "for df in dfs.values():\n",
    "    core_cols &= set(df.columns)\n",
    "core_cols = sorted(core_cols)\n",
    "\n",
    "# 3) Trim, tag year, drop missing mastid\n",
    "normalized = []\n",
    "for yy, df in dfs.items():\n",
    "    sub = df[core_cols].copy()\n",
    "    sub['year'] = 2000 + yy\n",
    "    sub = sub.dropna(subset=['mastid'])\n",
    "    normalized.append(sub)\n",
    "\n",
    "exit = pd.concat(normalized, ignore_index=True)\n",
    "def clean_bytes(val):\n",
    "    if isinstance(val, bytes):\n",
    "        return str(val)[2:-1]  # str(b'xyz') => \"b'xyz'\" → \"xyz\"\n",
    "    return val\n",
    "for col in exit.columns:\n",
    "    exit[col] = exit[col].apply(clean_bytes)\n",
    "    print(col)\n",
    "\n",
    "#exit.to_csv(\"/Users/adamcartwright/NCERDC-MODEL/data/exit_master.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16faae98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year              0\n",
      "aig               0\n",
      "mastid            0\n",
      "schlcode          0\n",
      "lea               0\n",
      "exit_code_desc    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Combine “effective” and raw exit codes into a single, complete field\n",
    "exit['final_exit_code'] = (\n",
    "    exit['effective_exit_code']        # the cleaned/standardized code\n",
    "        .fillna(exit['ex_exit_code'])  # if missing, fall back to the raw code\n",
    ")\n",
    "\n",
    "# Once coalesced, drop the old source columns\n",
    "exit = exit.drop(columns=['ex_exit_code', 'effective_exit_code'])\n",
    "\n",
    "# Define human‐readable labels for each code (0–9 and A–D)\n",
    "exit_code_map = {\n",
    "    '0': 'Has not left school',\n",
    "    '1': 'Transferred to another school in same LEA',\n",
    "    '2': 'Transferred to another system',\n",
    "    '3': 'Left the state',\n",
    "    '4': 'Dropped Out',\n",
    "    '5': 'Temporary Leave',\n",
    "    '6': 'Death',\n",
    "    '7': 'Other',\n",
    "    '8': 'Visiting Student',\n",
    "    '9': 'Graduated',\n",
    "    'A': 'Transferred to a private school within the state',\n",
    "    'B': 'Transferred to home school within the state',\n",
    "    'C': 'Transferred to a community college',\n",
    "    'D': 'Certificate recipient',\n",
    "}\n",
    "\n",
    "# Map each code to its description; any unmapped code becomes “Other”\n",
    "exit['exit_code_desc'] = (\n",
    "    exit['final_exit_code']\n",
    "        .map(exit_code_map)\n",
    "        .fillna('Other')\n",
    ")\n",
    "\n",
    "# List of demographic/timing vars that each have exactly 968 missing values\n",
    "vars_968 = [\n",
    "    'aig',\n",
    "    'eds',\n",
    "    'effective_g9year',\n",
    "    'els',\n",
    "    'en_g9school',\n",
    "    'init_collection',\n",
    "    'init_grade',\n",
    "    'init_year',\n",
    "    'last_collection',\n",
    "    'last_year',\n",
    "    'mig',\n",
    "    'sex',\n",
    "    'swd'\n",
    "]\n",
    "\n",
    "# Identify rows where _all_ of those vars are missing\n",
    "mask_all_missing = exit[vars_968].isna().all(axis=1)\n",
    "\n",
    "# Drop those 960 completely-blank-demographic rows\n",
    "exit = exit.loc[~mask_all_missing].copy()\n",
    "\n",
    "# 1) Define your essential columns\n",
    "essentials = ['year', 'aig', 'mastid', 'schlcode', 'lea', 'exit_code_desc']\n",
    "\n",
    "# 2) Subset to only those columns\n",
    "exit_essentials = exit[essentials].copy()\n",
    "\n",
    "# 3) (Optional) Double-check for any NAs just to be safe\n",
    "print(exit_essentials.isna().sum())\n",
    "\n",
    "# 4) Now exit_essentials is your final ML-ready table\n",
    "exit_essentials.to_csv(\n",
    "    \"../data/exit_master.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03e99cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit = exit[exit['exit_code_desc'].isin(['Dropped Out', 'Graduated'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8776ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'year' is numeric if needed\n",
    "exit['year'] = pd.to_numeric(exit['year'], errors='coerce')\n",
    "\n",
    "# Drop rows where year is missing\n",
    "exit = exit.dropna(subset=['year'])\n",
    "\n",
    "# Keep the earliest year per mastid\n",
    "exit = exit.sort_values('year').drop_duplicates(subset='mastid', keep='first')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ecea8875",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit.drop(columns=['acchome_accepted','auto_xfer_school','base_school','count_row_pre','count_row_state','dc_g9year','den','els_year_exited','en_five_year','en_g9school','en_g9year','ex_xfer_school','exit_exempt','g9year_missing','gdvr','gdvr_document_type','gdvr_school','gdvr_year','in_cohort','init_collection','last_collection','num','ps_g9year','rc_g9year','swd_latest_school','swd_latest_year','final_exit_code'],inplace=True)\n",
    "exit.dropna(inplace=True)\n",
    "exit.drop(columns=['last_year','init_year'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_ids = exit[['mastid', 'effective_g9year','exit_code_desc']].dropna(subset=['mastid'])\n",
    "\n",
    "# Drop duplicates if a mastid might appear more than once\n",
    "exit_ids = exit_ids.drop_duplicates(subset='mastid')\n",
    "\n",
    "# Save to CSV\n",
    "exit_ids.to_csv('../data/exit_mastids.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be4b0f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit.drop(columns=['year','effective_g9year','init_grade'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9077b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit.to_csv(\"../data/exit_mastid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7570245b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['effective_g9year'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m exit_ids = \u001b[43mexit\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmastid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43meffective_g9year\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mexit_code_desc\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.dropna(subset=[\u001b[33m'\u001b[39m\u001b[33mmastid\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Drop duplicates if a mastid might appear more than once\u001b[39;00m\n\u001b[32m      4\u001b[39m exit_ids = exit_ids.drop_duplicates(subset=\u001b[33m'\u001b[39m\u001b[33mmastid\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/pandas/core/frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/pandas/core/indexes/base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/pandas/core/indexes/base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['effective_g9year'] not in index\""
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
