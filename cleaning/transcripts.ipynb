{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 done\n",
      "19 done\n",
      "20 done\n",
      "21 done\n",
      "22 done\n",
      "23 done\n",
      "nas\n",
      "lea\n",
      "schlcode\n",
      "course_desc\n",
      "grade\n",
      "credit_value\n",
      "credit_value_earned\n",
      "final_mark\n",
      "academic_level_desc\n",
      "extra_gpa_point\n",
      "include_in_gpa\n",
      "include_in_honour_role\n",
      "include_in_ranking\n",
      "mastid\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "transcripts = pd.DataFrame()\n",
    "for year in range(18, 24):  # range is exclusive at the end\n",
    "    filename = f\"/Users/danielmatten/Desktop/m/transcripts20{year}.sas7bdat\"\n",
    "    try:\n",
    "        # Read SAS file\n",
    "        df = pd.read_sas(filename)\n",
    "\n",
    "        # Keep only relevant columns\n",
    "        df.columns = df.columns.str.lower()\n",
    "\n",
    "        # Drop missing values\n",
    "\n",
    "        \n",
    "        # Append to the main DataFrame\n",
    "        transcripts = pd.concat([transcripts, df], ignore_index=True)\n",
    "        print(f\"{year} done\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filename} not found. Skipping.\")\n",
    "    except KeyError:\n",
    "        print(f\"Required columns not found in {filename}. Skipping.\")\n",
    "def clean_bytes(val):\n",
    "    if isinstance(val, bytes):\n",
    "        return str(val)[2:-1]  # str(b'xyz') => \"b'xyz'\" → \"xyz\"\n",
    "    return val\n",
    "# Drop unnecessary columns\n",
    "transcripts.drop(columns=['semester', 'how_taken_desc', 'course_length_desc','school','completed_date','course_code'], inplace=True)\n",
    "\n",
    "# Drop rows where 'mastid' is NaN\n",
    "transcripts.dropna(subset=['mastid'], inplace=True)\n",
    "print(\"nas\")\n",
    "# Decode bytes to string in all columns (no slicing needed)\n",
    "for col in transcripts.columns:\n",
    "    transcripts[col] = transcripts[col].apply(clean_bytes)\n",
    "    print(col)\n",
    "\n",
    "transcripts.dropna(inplace=True) #this is pretty safe\n",
    "\n",
    "transcripts.to_csv(\"../data/transcripts_master.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── GPA HELPER FUNCTIONS ───────────────────────────────────────────────────────\n",
    "\n",
    "def final_mark_to_letter(mark):\n",
    "    \"\"\"\n",
    "    Convert a final_mark (numeric 0–100 or a letter) into a standardized letter grade:\n",
    "      - If it can be cast to float, map 90–100→\"A\", 80–89→\"B\", 70–79→\"C\", 60–69→\"D\", <60→\"F\"\n",
    "      - Otherwise, assume it’s already a letter string (e.g. \"A\", \"B+\", \"C-\", etc.)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        score = float(mark)\n",
    "        if score >= 90:\n",
    "            return \"A\"\n",
    "        elif score >= 80:\n",
    "            return \"B\"\n",
    "        elif score >= 70:\n",
    "            return \"C\"\n",
    "        elif score >= 60:\n",
    "            return \"D\"\n",
    "        else:\n",
    "            return \"F\"\n",
    "    except:\n",
    "        return str(mark).strip().upper()\n",
    "\n",
    "base_points_map = {\n",
    "    \"A+\": 4.0, \"A\": 4.0, \"A-\": 4.0,\n",
    "    \"B+\": 3.0, \"B\": 3.0, \"B-\": 3.0,\n",
    "    \"C+\": 2.0, \"C\": 2.0, \"C-\": 2.0,\n",
    "    \"D+\": 1.0, \"D\": 1.0, \"D-\": 1.0,\n",
    "    \"F\": 0.0\n",
    "}\n",
    "\n",
    "def extra_weight(level):\n",
    "    \"\"\"\n",
    "    Map academic_level_desc codes to extra GPA weight:\n",
    "      - 5 → Honors/Advanced/AIG   → +0.5\n",
    "      - 7 → Advanced Placement     → +1.0\n",
    "      - 8 → International Baccalaureate → +1.0\n",
    "      - Otherwise → 0.0\n",
    "    \"\"\"\n",
    "    try:\n",
    "        lvl = int(level)\n",
    "        if lvl == 5:\n",
    "            return 0.5\n",
    "        elif lvl in (7, 8):\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.0\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "# ─── 1) Copy & normalize ────────────────────────────────────────────────────────\n",
    "df = transcripts.copy()\n",
    "# ensure datetime\n",
    "df[\"completed_date\"] = pd.to_datetime(df[\"completed_date\"], errors=\"coerce\")\n",
    "df[\"year\"]           = df[\"completed_date\"].dt.year.astype(\"Int64\")\n",
    "\n",
    "# ─── 2) Filter to HS grades & GPA-eligible ───────────────────────────────────────\n",
    "df[\"grade_int\"] = pd.to_numeric(df[\"grade\"], errors=\"coerce\").astype(\"Int64\")\n",
    "df = df.loc[\n",
    "    df[\"grade_int\"].between(9, 12) &\n",
    "    (df[\"include_in_gpa\"] == \"Y\")\n",
    "].copy()\n",
    "\n",
    "# ─── 4) GPA points & quality points ─────────────────────────────────────────────\n",
    "# letter → base points → extra weight → capped weighted points\n",
    "df[\"letter_grade\"]         = df[\"final_mark\"].apply(final_mark_to_letter)\n",
    "df[\"base_grade_point\"]     = df[\"letter_grade\"].map(base_points_map)\n",
    "df[\"extra_gpa_weight\"]     = df[\"academic_level_desc\"].apply(extra_weight)\n",
    "df[\"weighted_grade_point\"] = (\n",
    "    df[\"base_grade_point\"] + df[\"extra_gpa_weight\"]\n",
    ").clip(upper=5.0)\n",
    "\n",
    "# credits\n",
    "df[\"credit_value_earned\"] = pd.to_numeric(df[\"credit_value_earned\"], errors=\"coerce\")\n",
    "df[\"credit_value\"]        = pd.to_numeric(df[\"credit_value\"], errors=\"coerce\")\n",
    "df[\"credits_for_calc\"]    = df[\"credit_value_earned\"].fillna(df[\"credit_value\"])\n",
    "\n",
    "# quality points\n",
    "df[\"qp_unweighted\"] = df[\"base_grade_point\"]     * df[\"credits_for_calc\"]\n",
    "df[\"qp_weighted\"]   = df[\"weighted_grade_point\"] * df[\"credits_for_calc\"]\n",
    "\n",
    "# ─── 5) Cumulative sums & GPAs ──────────────────────────────────────────────────\n",
    "df = df.sort_values([\"mastid\", \"year\"])\n",
    "df[[\"csum_credits\",\"csum_qp_uw\",\"csum_qp_w\"]] = (\n",
    "    df.groupby(\"mastid\")[[\"credits_for_calc\",\"qp_weighted\",\"qp_weighted\"]]\n",
    "      .cumsum()\n",
    ")\n",
    "\n",
    "df[\"gpa_weighted_cum\"] = (df[\"csum_qp_uw\"] / df[\"csum_credits\"]).round(3)\n",
    "df[\"gpa_weighted_cum\"]   = (df[\"csum_qp_w\"]  / df[\"csum_credits\"]).round(3)\n",
    "\n",
    "# ─── 6) Collapse to one row per student/school/year ──────────────────────────────\n",
    "gpa_yearly = (\n",
    "    df.groupby([\"mastid\",\"year\"], as_index=False)\n",
    "      .agg({\n",
    "         \"gpa_unweighted_cum\":\"last\",\n",
    "         \"gpa_weighted_cum\":\"last\",\n",
    "         \"csum_credits\":\"last\"\n",
    "      })\n",
    "      .rename(columns={\n",
    "         \"csum_credits\":\"total_credits_cum\"\n",
    "      })\n",
    ")\n",
    "\n",
    "# clean up types & drop empties\n",
    "gpa_yearly[\"mastid\"] = gpa_yearly[\"mastid\"].astype(int)\n",
    "gpa_yearly.dropna(subset=[\"gpa_unweighted_cum\"], inplace=True)\n",
    "\n",
    "# ─── 7) Save ────────────────────────────────────────────────────────────────────\n",
    "out_path = \"/Users/adamcartwright/ncerdc-model/data/transcripts_gpa_by_year.csv\"\n",
    "gpa_yearly.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mapping based on the examples you gave\n",
    "conversion_map = {\n",
    "    '0': 'Modified Curriculum',\n",
    "    '1': 'Abridged/Adapted (Remedial)',\n",
    "    '2': 'Standard Version',\n",
    "    '5': 'Honors/Advanced/Academically Gifted',\n",
    "    '6': 'Co-op Education',\n",
    "    '7': 'Advanced Placement',\n",
    "    '8': 'International Baccalaureate',\n",
    "    '9': 'Non-Classroom Activity'\n",
    "}\n",
    "\n",
    "def convert_to_description(val):\n",
    "    val = str(val).strip()\n",
    "    return conversion_map.get(val[0], val) if val else val\n",
    "\n",
    "# Apply to your column (replace 'your_column' with the actual name)\n",
    "transcripts['academic_level_desc'] = transcripts['academic_level_desc'].apply(convert_to_description)\n",
    "\n",
    "transcripts = transcripts[transcripts['include_in_gpa'] == 'Y']\n",
    "\n",
    "letter_to_score = {\n",
    "    'A+': 98,\n",
    "    'A': 95,\n",
    "    'A-': 91,\n",
    "    'B+': 88,\n",
    "    'B': 85,\n",
    "    'B-': 81,\n",
    "    'C+': 78,\n",
    "    'C': 75,\n",
    "    'C-': 71,\n",
    "    'D+': 68,\n",
    "    'D': 65,\n",
    "    'D-': 61,\n",
    "    'F': 50,\n",
    "    'P': None,   # Pass/fail — handle as missing or special flag\n",
    "    'W': None,   # Withdrawn — usually not a valid mark\n",
    "    'INC': None, # Incomplete\n",
    "    'EX': None   # Exempt\n",
    "}\n",
    "\n",
    "def convert_final_mark(val):\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Try converting to float (for numeric values)\n",
    "        num = float(val)\n",
    "        if 0 <= num <= 100:\n",
    "            return num\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Handle letter grades\n",
    "    val_str = str(val).strip().upper()\n",
    "    return letter_to_score.get(val_str, None)\n",
    "\n",
    "transcripts['final_mark'] = transcripts['final_mark'].apply(convert_final_mark)\n",
    "\n",
    "transcripts.dropna(subset=['final_mark'])\n",
    "max_classes = 50\n",
    "\n",
    "# Sort and rank\n",
    "transcripts_sorted = transcripts.sort_values(by=['mastid', 'grade', 'academic_level_desc'])\n",
    "transcripts_sorted['class_rank'] = transcripts_sorted.groupby('mastid').cumcount() + 1\n",
    "\n",
    "# Trim long histories\n",
    "transcripts_trimmed = transcripts_sorted[transcripts_sorted['class_rank'] <= max_classes]\n",
    "\n",
    "# Pivot helper\n",
    "def pivot_feature(df, colname):\n",
    "    out = df.pivot(index='mastid', columns='class_rank', values=colname)\n",
    "    out.columns = [f\"{colname}_{i}\" for i in out.columns]\n",
    "    return out\n",
    "\n",
    "# Pivot all desired features\n",
    "features = {\n",
    "    'course_desc': pivot_feature(transcripts_trimmed, 'course_desc'),\n",
    "    'grade': pivot_feature(transcripts_trimmed, 'grade'),\n",
    "    'academic_level_desc': pivot_feature(transcripts_trimmed, 'academic_level_desc'),\n",
    "    'final_mark': pivot_feature(transcripts_trimmed, 'final_mark')\n",
    "}\n",
    "\n",
    "# Base student info — from the full transcripts, not trimmed\n",
    "student_info = transcripts.groupby('mastid')[['lea', 'schlcode']].first()\n",
    "\n",
    "# Merge all\n",
    "student_df = student_info.copy()\n",
    "for df in features.values():\n",
    "    student_df = student_df.merge(df, left_index=True, right_index=True, how='left')\n",
    "\n",
    "# Reset index for ML-ready DataFrame\n",
    "student_df = student_df.reset_index()\n",
    "\n",
    "student_df.to_csv(\"../data/transcripts_pivoted.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpa_yearly = pd.read_csv(\"../data/transcripts_gpa_by_year.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpa_yearly = gpa_yearly[gpa_yearly['year'] > 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_ids = pd.read_csv('../data/exit_list.csv')\n",
    "filtered = gpa_yearly.merge(exit_ids,on='mastid',how='inner')\n",
    "filtered = filtered[filtered['mastid'].isin(exit_ids['mastid'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate grade\n",
    "filtered['grade'] = filtered['year']-filtered['effective_g9year']  + 9\n",
    "\n",
    "# Drop the original columns\n",
    "filtered = filtered.drop(columns=['year', 'effective_g9year','total_credits_cum'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot on both GPA columns per grade\n",
    "pivot_df = filtered.pivot(index='mastid', columns='grade', values=['gpa_unweighted_cum', 'gpa_weighted_cum'])\n",
    "\n",
    "# Flatten MultiIndex columns\n",
    "pivot_df.columns = [f'{col[0]}_grade_{int(col[1])}' for col in pivot_df.columns]\n",
    "\n",
    "# Reset index if you want mastid as a column\n",
    "pivot_df = pivot_df.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_grades = [9, 10, 11, 12]\n",
    "required_cols = [f'gpa_unweighted_cum_grade_{g}' for g in required_grades]\n",
    "\n",
    "# Keep only rows with all 4 grades present\n",
    "pivot_df = pivot_df.dropna(subset=required_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df.drop(columns=['gpa_unweighted_cum_grade_7','gpa_unweighted_cum_grade_8','gpa_unweighted_cum_grade_13','gpa_unweighted_cum_grade_14','gpa_unweighted_cum_grade_15','gpa_unweighted_cum_grade_16','gpa_unweighted_cum_grade_17','gpa_unweighted_cum_grade_21','gpa_unweighted_cum_grade_22'],inplace=True)\n",
    "pivot_df.drop(columns=['gpa_weighted_cum_grade_7','gpa_weighted_cum_grade_8','gpa_weighted_cum_grade_13','gpa_weighted_cum_grade_14','gpa_weighted_cum_grade_15','gpa_weighted_cum_grade_16','gpa_weighted_cum_grade_17','gpa_weighted_cum_grade_21','gpa_weighted_cum_grade_22'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df.to_csv(\"../data/transcripts_mastid.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
